{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZbhTAYbclQ7"
      },
      "source": [
        "# Assignment 2: Sequence Labeling\n",
        "\n",
        "TA contact for this assignment: Aayush Sheth (aayush.sheth@duke.edu),\n",
        "Raymond Xiong (raymond.xiong@duke.edu)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In this assignment you will implement two sequence labeling models (HMMs and CRFs) for the task of named-entity recognition (NER).\n",
        "- You will start by implementing the count-based MLE estimator for HMM parameters, followed by the Viterbi algorithm for running inference using HMMs.\n",
        "- Then you will implement the forward algorithm and gradient based MLE training for CRFs.\n",
        "- Lastly, you will try to improve the CRF by adding extensions.\n",
        "\n",
        "You should **NOT** call existing CRF libraries in your solution.\n",
        "\n",
        "**Warning**: As usual, please don't start the day before it is due! Some parts may require significant debugging.\n",
        "\n",
        "For this assignment we will use the CoNLL 2003 dataset which contains sentences\n",
        "labeled with 4 types of entities -- PER, ORG, LOC and MISC. We will again filter out rare words and replace them with an `<unk>` token.\n",
        "\n",
        "**Note**: You do **not** need a GPU for this assignment unless, as part of the extension, you implement a neural CRF. If you do decide to use the GPU, please only do so when needed to avoid getting locked out of colab. You can enable / disable GPU usage by changing the Runtime type under the Runtime menu.\n",
        "\n",
        "**Grading Rubric**\n",
        "- 70% results\n",
        " - 15% `viterbi_vals.npy` (Viterbi correctness)\n",
        " - 15% `hmm_predictions.json` (meets target)\n",
        " - 15% `forward_vals.npy` (forward algorithm correctness)\n",
        " - 15% `crf_predictions.json` (meets target)\n",
        " - 10% `crf_predictions.json` (improvement)\n",
        "  \n",
        "- 30% writeup\n",
        " - 12.5% clarity\n",
        " - 12.5% correctness\n",
        " - 5% interestingness of ideas\n",
        "\n",
        "\n",
        "Before starting on the assignment please make your own copy and rename it `proj_2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDFPmdK1cUEM",
        "outputId": "0e5fcbf1-d587-4329-d76b-9f5e4c766a56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets==2.19.0 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (2.19.0)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from datasets==2.19.0) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from datasets==2.19.0) (2.0.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from datasets==2.19.0) (19.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from datasets==2.19.0) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from datasets==2.19.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from datasets==2.19.0) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from datasets==2.19.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from datasets==2.19.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from datasets==2.19.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from datasets==2.19.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.0) (2024.3.1)\n",
            "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from datasets==2.19.0) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from datasets==2.19.0) (0.28.1)\n",
            "Requirement already satisfied: packaging in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from datasets==2.19.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from datasets==2.19.0) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from aiohttp->datasets==2.19.0) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from aiohttp->datasets==2.19.0) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from aiohttp->datasets==2.19.0) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from aiohttp->datasets==2.19.0) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from aiohttp->datasets==2.19.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from aiohttp->datasets==2.19.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from aiohttp->datasets==2.19.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from aiohttp->datasets==2.19.0) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets==2.19.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.19.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.19.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.19.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.19.0) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from pandas->datasets==2.19.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from pandas->datasets==2.19.0) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from pandas->datasets==2.19.0) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.19.0) (1.16.0)\n",
            "Requirement already satisfied: seqeval in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from seqeval) (2.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.15.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "# Install some required packages.\n",
        "!pip install datasets==2.19.0\n",
        "!pip install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GW3MrWR4wK6S"
      },
      "outputs": [],
      "source": [
        "## important imports; feel free to import other libraries here (that don't already implement what you are supposed to).\n",
        "from collections import defaultdict, Counter, OrderedDict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import tqdm\n",
        "import datasets\n",
        "import numpy as np\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkD8N4_GH0AB"
      },
      "source": [
        "We will use the `datasets` library to load the CoNLL 2003 dataset. An example in this dataset includes a pair of sequences $x$ and $y$, where $x$ is a sequence of tokens and $y$ is a sequence of labels encoded using the BIO scheme. E.g.,\n",
        "\n",
        "```\n",
        "x = Singapore Refining Company expected to shut CDU 3.\n",
        "y = B-ORG I-ORG I-ORG O O O B-ORG I-ORG O\n",
        "```\n",
        "\n",
        "In this example, there are two entities present: `Singapore Refining Company`\n",
        "and `CDU 3`, both of type ORG.\n",
        "\n",
        "The code below also implements a helper class for sampling batches which contain only sequences of the same length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348,
          "referenced_widgets": [
            "c4bdb4353323484585bb50b68d5764c8",
            "6f57783a3fd84d6d81cea97b459cfe73",
            "d8c42315171d4e5daddea712222661a1",
            "0e3a6101cd064827bf5ddba9e8c6b7f3",
            "361459d739954d48b348b054a7a3136e",
            "c3db8635d83c4c4989cfbde399e36299",
            "5202ccc43ad54e3e9bcbf104e845d85a",
            "61941d4e7273429dbde90078d39cc7b2",
            "65e6df0e0b604a99a23294901acd9e19",
            "1b6a2ac6983745a48a269bf4d6a7dc77",
            "ed4deccbde194ff0b69c4d15ece2e6e3",
            "61869919871e417f9aef1c48cb85967b",
            "3b3eb0307f1242c18f51cded81b3ff9f",
            "0d668b611b7f416a95b3299856ba3e4b",
            "649ed9285d3845b0a1cb537eb185039d",
            "ec7646544c644a6c89d501f35ac3d877",
            "c7a0c13ef3dd4966895d437df1cd15a2",
            "7cb7c5b17e1f4c85a89998c33b5f6b30",
            "b7575e83a7254f17a644d41a42d9449f",
            "951581a5c0e04bc88b77c5c4938c3800",
            "6242e1267f5c40909826cbf7bf02e723",
            "ea9b2c94235f454d9bcdaf4cdca0028d",
            "68cda39013b54ab8a518dc947734c91b",
            "7312b7cfca104be7bd309c03c3a48e4c",
            "57bd92df3e794fefbd5ee6024b7f75a4",
            "fc5e733df89d4df6aa7d003ce3fdae5f",
            "a76bb0bbb47946aa9d28220ae3f701e4",
            "06e8d9144da14c8da7489a2556e5457c",
            "72feee3b2b6c40c2a25d3519e828b39a",
            "cd040b81e72e4078b6a4c39a36b55cf7",
            "36536a1aa8644836837ca6b8601b39e3",
            "8581f9998bf1468b9d2cfc480dfde65e",
            "93033a1e381b49ab9971e8bae6d3011c",
            "3dc4decface443b4b83da1830217f256",
            "f17611c5c1894a158c1810a071c7ed26",
            "8fd0e19e6ce74aacb5f8f9b17c5a906b",
            "4c914b6f5dfd4962a1438f736db1004a",
            "3b061c108ab249f3826419ea224fd054",
            "8b1dad8582884cbda6e476b5b3d52eeb",
            "1bde6f946d474cdb9a70d02417b6e8d9",
            "e451f908a44c465a831258bff2c94673",
            "f0a618b3f1bd42159ea8a7b5d6c8874a",
            "75b55292650242c4a982e22b99f7b75d",
            "14becfbe34674619a8f0cc8974a929f5",
            "8f7c8ca70c0c4083bfe80715f444868c",
            "525e104d92e9455eac4e5fc46198bdcd",
            "64611014d6c24b1f952af475573ce7ce",
            "ee5fe82b8add4905a682270baa3e6401",
            "e43cd6e248574d9fb1fbe08c540d80f7",
            "0075c205c0434cd3b5799924bc82f493",
            "db071929ecc34879a4f58cbb151335d0",
            "8e973317461e459396fc302090f4323d",
            "a01d0993265248569e958aa0eb58a8cf",
            "17a07ecc939a4607a85a5b34550847ba",
            "6a86b21eba374c0fae5d64a0e2ae01f4",
            "0df2d42685fc423a984985f71733e4c2",
            "ce8941fd049b4f26ad118d952fab0273",
            "2a96e5b30c5045ef8695bcfc4bafe00b",
            "b8a8449c5cd84e1295f3c3dd7b3dc1f3",
            "c7eed34ed19d4c978e1ca01b48f22aa9",
            "31a59ec567194230adf4e7d22b4e86d5",
            "4dfc08556897472bbc2cdda58aef5b6b",
            "0b9ce3e63edf4b07b92c62d351502bf0",
            "8137f6ce5fe9446d919239bfafb666bc",
            "6b93152dee384f2091b0c3bb8137bfaf",
            "f1675ab219d348c0b4c7bf5cb97f1c26"
          ]
        },
        "id": "0vnguf9nckp_",
        "outputId": "94eb3597-b3c8-44ac-a87b-8440e0a83ec4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for conll2003 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/conll2003\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "labels ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'] (total 9 )\n",
            "using a vocabulary of size 11983\n"
          ]
        }
      ],
      "source": [
        "## Data setup. Please do NOT change any of this.\n",
        "nerdata = datasets.load_dataset(\"conll2003\")\n",
        "\n",
        "# get label types and indices\n",
        "label_types = nerdata[\"train\"].features[\"ner_tags\"].feature.names\n",
        "label_type2idx = {labeltype: i for i, labeltype in enumerate(label_types)}\n",
        "\n",
        "# get word types and indices\n",
        "min_freq = 2 # any word occuring < min_freq times gets <unk>ed\n",
        "word_counter = Counter()\n",
        "for example in nerdata[\"train\"]:\n",
        "    word_counter.update(example[\"tokens\"])\n",
        "word_types = [\"<unk>\"] + [wtype for (wtype, wcount) in word_counter.most_common()\n",
        "                          if wcount >= min_freq]\n",
        "word_type2idx = {wordtype: i for i, wordtype in enumerate(word_types)}\n",
        "\n",
        "def word2idx(word):\n",
        "    return word_type2idx[word] if word in word_type2idx else word_type2idx[\"<unk>\"]\n",
        "\n",
        "print(\"labels\", label_types, \"(total\", len(label_types), \")\")\n",
        "print(\"using a vocabulary of size\", len(word_types))\n",
        "\n",
        "# only keep the tokens and ner tags.\n",
        "trdata, valdata = nerdata[\"train\"], nerdata[\"validation\"]\n",
        "trdata.set_format(columns=['tokens', 'ner_tags'])\n",
        "valdata.set_format(columns=['tokens', 'ner_tags'])\n",
        "\n",
        "def collate(batchdictseq):\n",
        "    batchdict = {\"tokens\": [x[\"tokens\"] for x in batchdictseq]}\n",
        "    batchdict[\"ner_tags\"] = [x[\"ner_tags\"] for x in batchdictseq]\n",
        "\n",
        "    wordseqs = torch.LongTensor([[word2idx(word) for word in wordlist] # batchsize x M\n",
        "                                 for wordlist in batchdict['tokens']])\n",
        "    tgtseqs = torch.LongTensor(batchdict[\"ner_tags\"]) # these are already indices\n",
        "    return wordseqs, tgtseqs\n",
        "\n",
        "class FeaturizedDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, list_of_dicts):\n",
        "        super().__init__()\n",
        "        self.list_of_dicts = list_of_dicts\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if isinstance(index, list):\n",
        "            batch = {}\n",
        "            for rulidx in index:\n",
        "                for key, val in self.list_of_dicts[rulidx].items():\n",
        "                    if key not in batch:\n",
        "                        batch[key] = [val]\n",
        "                    else:\n",
        "                        batch[key].append(val)\n",
        "            return batch\n",
        "        return self.list_of_dicts[index]\n",
        "\n",
        "\n",
        "class ByLengthSampler(torch.utils.data.Sampler):\n",
        "    \"\"\"\n",
        "    Allows for sampling minibatches of examples all of the same sequence length;\n",
        "    adapted from https://discuss.pytorch.org/t/tensorflow-esque-bucket-by-sequence-length/41284/13.\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, key, batchsize, shuffle=True):\n",
        "        # import ipdb\n",
        "        # ipdb.set_trace()\n",
        "        self.batchsize = batchsize\n",
        "        self.shuffle = shuffle\n",
        "        self.seqlens = torch.LongTensor([len(example[key]) for example in dataset])\n",
        "        self.nbatches = len(self._generate_batches())\n",
        "\n",
        "    def _generate_batches(self):\n",
        "        # shuffle examples\n",
        "        seqlens = self.seqlens\n",
        "        perm = torch.randperm(seqlens.size(0)) if self.shuffle else torch.arange(seqlens.size(0))\n",
        "        batches = []\n",
        "        len2batch = defaultdict(list)\n",
        "        for i, seqidx in enumerate(perm):\n",
        "            seqlen, seqidx = seqlens[seqidx].item(), seqidx.item()\n",
        "            len2batch[seqlen].append(seqidx)\n",
        "            if len(len2batch[seqlen]) >= self.batchsize:\n",
        "                batches.append(len2batch[seqlen][:])\n",
        "                del len2batch[seqlen]\n",
        "        # add any remaining batches\n",
        "        for length, batchlist in len2batch.items():\n",
        "            if len(batchlist) > 0:\n",
        "                batches.append(batchlist)\n",
        "        # shuffle again so we don't always start w/ the most common sizes\n",
        "        batchperm = torch.randperm(len(batches)) if self.shuffle else torch.arange(len(batches))\n",
        "        return [batches[idx] for idx in batchperm]\n",
        "\n",
        "    def batch_count(self):\n",
        "        return self.nbatches\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.seqlens)\n",
        "\n",
        "    def __iter__(self):\n",
        "        batches = self._generate_batches()\n",
        "        for batch in batches:\n",
        "            yield batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijsehFjoMA2S"
      },
      "source": [
        "You will need to submit some predictions from the models you implement to GradeScope for us to grade.  The following will download the required files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Slb1roUyL_du",
        "outputId": "73c62868-7485-4f6e-ea7f-73f212a67ed9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zug6hfB1Gq_2UU5oJ5QtOIdNoC0SXnjb\n",
            "To: /Users/yd211/Documents/GitHub/CS_590/HW2/test_data_nolabel.json\n",
            "100%|█████████████████████████████████████████| 192k/192k [00:00<00:00, 651kB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1zug6hfB1Gq_2UU5oJ5QtOIdNoC0SXnjb\n",
        "with open(\"test_data_nolabel.json\", \"r\") as f:\n",
        "  testdata = json.load(f)\n",
        "testdata = FeaturizedDataset(testdata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfJ0VlE_iEG-"
      },
      "source": [
        "You will also need to submit the outputs of your `viterbi` and `forward_alg` implementations (see below) on Gradescope; the following code will save these outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9HTPS5HhitoG"
      },
      "outputs": [],
      "source": [
        "def save_alg_outputs(alg=\"viterbi\"):\n",
        "    \"\"\"\n",
        "    Please do not edit this function\n",
        "    \"\"\"\n",
        "    bsz, N = 4, 100\n",
        "    if alg == \"viterbi\":\n",
        "        outfi = 'viterbi_vals.npy'\n",
        "        results = np.zeros((N, bsz, N+1), dtype=np.float32)\n",
        "    else:\n",
        "        outfi = 'forward_vals.npy'\n",
        "        results = np.zeros((N, bsz), dtype=np.float32)\n",
        "\n",
        "    for i in tqdm.notebook.tqdm(range(2, N+2)):\n",
        "        torch.manual_seed(int(alg == \"viterbi\")*590 + i)\n",
        "        K = torch.randint(2, 11, (1,)).item()\n",
        "        psi0 = torch.randn(bsz, K)\n",
        "        psis = torch.randn(bsz, i-1, K, K)\n",
        "        if alg == \"viterbi\":\n",
        "            max_scores, argmax_seqs = viterbi(psi0, psis)\n",
        "            results[i-2, :, :i] = argmax_seqs.float().numpy()\n",
        "            results[i-2, :, N] = max_scores.numpy()\n",
        "        else:\n",
        "            log_Zs = forward_alg(psi0, psis)\n",
        "            results[i-2] = log_Zs.numpy()\n",
        "\n",
        "    np.save(outfi, results)\n",
        "    print(\"saved to\", outfi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j49UexfOIGkw"
      },
      "source": [
        "### Sequence prediction evaluation\n",
        "\n",
        "We will use the following `eval_predictions` function to get predictions from both HMMs and CRFs and compute precision, recall and F1 scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5q5UiZV8wwWc"
      },
      "outputs": [],
      "source": [
        "def eval_predictions(loader, model, nbatches=None, show_f1=True):\n",
        "    \"\"\"\n",
        "    Computes predictions and prints the Prec / Rec / F1 scores.\n",
        "\n",
        "    args:\n",
        "      - loader: a torch.utils.data.DataLoader\n",
        "      - model: a SequenceModel (see below) which implements the predict function\n",
        "\n",
        "    returns:\n",
        "      - all_preds: a list of all label sequence predictions (themselves lists)\n",
        "    \"\"\"\n",
        "    if not nbatches:\n",
        "      nbatches=loader.sampler.nbatches\n",
        "    metric = datasets.load_metric(\"seqeval\", trust_remote_code=True)\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for (X, Y) in tqdm.notebook.tqdm(loader, total=nbatches):\n",
        "            maxscores, preds = model.predict(X) # batchsize, batchsize x M\n",
        "            # map label indices back to labels\n",
        "            preds, Y = preds.tolist(), Y.tolist()\n",
        "            goldlabels = [[label_types[glabel] for glabel in goldseq]\n",
        "                          for goldseq in Y]\n",
        "            predlabels = [[label_types[plabel] for plabel in predseq]\n",
        "                          for predseq in preds]\n",
        "            all_preds.extend(predlabels)\n",
        "            metric.add_batch(predictions=predlabels, references=goldlabels)\n",
        "    results = metric.compute()\n",
        "    prec, rec = results['overall_precision'], results['overall_recall']\n",
        "    f1 = results['overall_f1']\n",
        "    if show_f1:\n",
        "        print(f\"Precision = {prec:6.3f}, Recall = {rec:6.3f}, F1 = {f1:6.3f}\")\n",
        "    return all_preds\n",
        "\n",
        "\n",
        "val_batchsize = 8\n",
        "\n",
        "# set up a validation set loader for running eval_predictions\n",
        "val_loader = torch.utils.data.DataLoader(valdata, batch_size=1,\n",
        "    batch_sampler=ByLengthSampler(valdata, 'tokens', val_batchsize, shuffle=False),\n",
        "    collate_fn=collate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wznXPR5xxT4H"
      },
      "source": [
        "# HMMs\n",
        "\n",
        "We have implemented nearly all of a simple hidden markov model (HMM) for you, below. Recall that an HMM can be described by three sets of parameters: the transition matrix $\\lambda$, the emission matrix $\\phi$ and the initial state distribution $\\mu$. The smoothed MLE estimate of each of these is given by,\n",
        "\n",
        "$$\\lambda_{i,j} = \\frac{\\#(y_{m-1}=i,y_m=j) +\\alpha}{\\#(y_{m-1}=i) +K\\alpha},$$\n",
        "\n",
        "$$\\phi_{i,k} = \\frac{\\#(y_{m}=i, w_m=k) + \\alpha}{\\#(y_m=i) +V\\alpha},$$\n",
        "\n",
        "$$\\mu_i = \\frac{\\#(y_0=i) + \\alpha}{N + K\\alpha},$$\n",
        "\n",
        "where $K$ is the number of labels, $V$ is vocabulary size, $\\#$ is the count of a given label / pair of labels / label and token, and $N$ is the total number of sequences in the training data. We will store these parameters in log space.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tl_Aj92sBVG"
      },
      "source": [
        "### **Implementation task \\#1**\n",
        "Please fill in the rest of the `mle_train` function below, which calculates the HMM parameter estimates from data. We have marked where in particular code needs to be filled in. The `mle_train` function consumes the `trdata` dataset defined above.\n",
        "\n",
        "After filling in `mle_train` you should be able to run the cell below.\n",
        "\n",
        "**TLDR:** Implement the rest of the `mle_train` function below and then run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TS_fiOR30Ihd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e894795f73d44b59bb10571f1e47866",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/14041 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "class SequenceModel:\n",
        "    def get_sequence_psis(self, X):\n",
        "      raise NotImplementedError()\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predicts on a single batch. Do not change this function.\n",
        "\n",
        "        args\n",
        "          - X: batchsize x M matrix of word type indices\n",
        "        \"\"\"\n",
        "        psi0, psis = self.get_sequence_psis(X)\n",
        "        return viterbi(psi0, psis)\n",
        "      \n",
        "class HMMModel(SequenceModel):\n",
        "    def __init__(self, K, V, word2idx):\n",
        "        \"\"\"\n",
        "        args\n",
        "          - K: an integer number of labels possible for each token\n",
        "          - V: the integer size of our vocabulary\n",
        "          - word2idx: a function mapping every possible word type to an index\n",
        "        \"\"\"\n",
        "        self.K, self.V = K, V # nlabels, vocab_size\n",
        "        self.lamb, self.phi, self.mu = None, None, None\n",
        "        self.word2idx = word2idx\n",
        "\n",
        "    def mle_train(self, dataset, smoothing=1e-3):\n",
        "        \"\"\"\n",
        "        args\n",
        "          - dataset: a datasets.arrow_dataset.Dataset (from Huggingface datasets library)\n",
        "          - smoothing: a float constant to be added to counts to smooth probabilities\n",
        "        \"\"\"\n",
        "        K, V = self.K, self.V\n",
        "        self.lamb = torch.zeros(K, K) + smoothing # transition probability matrix\n",
        "        self.phi = torch.zeros(K, V) + smoothing  # emission probability matrix\n",
        "        self.mu = torch.zeros(K) + smoothing      # initial state distribution\n",
        "\n",
        "        ### BEGIN YOUR CODE HERE!!!\n",
        "        #Your code start here\n",
        "        for example in tqdm.notebook.tqdm(dataset):\n",
        "            tokens, ner_tags = example[\"tokens\"], example[\"ner_tags\"]\n",
        "            # increment initial label count\n",
        "            self.mu[ner_tags[0]] += 1.0\n",
        "            for i in range(len(tokens)):\n",
        "                widx = self.word2idx(tokens[i])\n",
        "                self.phi[ner_tags[i], widx] += 1.0\n",
        "                if i > 0:\n",
        "                    self.lamb[ner_tags[i-1], ner_tags[i]] += 1.0\n",
        "\n",
        "        # normalize mu\n",
        "        self.mu = self.mu / self.mu.sum()\n",
        "\n",
        "        # normalize transition rows\n",
        "        self.lamb = self.lamb / self.lamb.sum(dim=1, keepdim=True)\n",
        "\n",
        "        # normalize emission rows\n",
        "        self.phi = self.phi / self.phi.sum(dim=1, keepdim=True)\n",
        "        #Your code end here\n",
        "        ### END YOUR CODE HERE\n",
        "\n",
        "        # now log everything\n",
        "        self.lamb.log_()\n",
        "        self.phi.log_()\n",
        "        self.mu.log_()\n",
        "\n",
        "\n",
        "    def get_sequence_psis(self, X):\n",
        "        \"\"\"\n",
        "        Precalculates scores for a batch of word sequences, so we can run Viterbi.\n",
        "\n",
        "        args\n",
        "          - X: batchsize x M matrix of word type indices\n",
        "\n",
        "        returns\n",
        "          - psi0: a tensor of real scores (which can be < 0), of dimension batchsize x K\n",
        "          - psis: a tensor of real scores (which can be < 0), of dimension batchsize x M-1 x K x K\n",
        "        \"\"\"\n",
        "        K = self.K\n",
        "        lamb, phi, mu = self.lamb, self.phi, self.mu\n",
        "\n",
        "        # recall that for an HMM, we have:\n",
        "        #      psi(w_{1:M}, y_m, y_{m-1}, m) = log p(y_m | y_{m-1}) + log p(w_m | y_m).\n",
        "        # so we'll precalculate these psis for all label-pairs, for all time-steps.\n",
        "\n",
        "        # select emission probabilities corresponding to first time-step (for each example).\n",
        "        log_initial_emissions = phi.t()[X[:, 0]] # batchsize x K\n",
        "        log_initial_probs = mu.view(1, self.K) # 1 x K\n",
        "        psi0 = log_initial_probs + log_initial_emissions\n",
        "\n",
        "        # select emission probabilities for the remaining time steps\n",
        "        log_emissions = phi.t()[X[:, 1:]] # batchsize x M-1 x K\n",
        "        # unsqueeze dim 2 of emissions since same emissions no matter what previous label was\n",
        "        log_emissions = log_emissions.unsqueeze(2) # batchsize x M-1 x 1 x K\n",
        "\n",
        "        # the transition probabilities are the same for every time step (and every example),\n",
        "        # so we unsqueeze the first 2 phi dimensions.\n",
        "        log_transitions = lamb.view(1, 1, K, K)\n",
        "\n",
        "        # add emission log prob for each state and time-step\n",
        "        psis = log_transitions + log_emissions\n",
        "        return psi0, psis\n",
        "\n",
        "hmm = HMMModel(len(label_types), len(word_types), word2idx)\n",
        "hmm.mle_train(trdata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb9OeY8OqZix"
      },
      "source": [
        "## The sequence scores defined by HMMs\n",
        "\n",
        "For HMMs we can define a score at each position $m$ and for every pair of labels as follows:\n",
        "\n",
        "$$\\psi(w_{1:M}, y_m, y_{m-1}, m) = \\log p(y_m | y_{m-1}) + \\log p(w_m | y_m)$$\n",
        "\n",
        "Thinking in terms of these local scores (rather than explicit log probabilities) will allow us to easily implement inference algorithms that work for both HMMs and CRFs.\n",
        "\n",
        "Accordingly, we have implemented the function `get_sequence_psis` in the HMM code above, which uses the trained HMM parameters to compute these local scores. In particular, `get_sequence_psis` returns `psi0` (batch-size x num-labels), the scores for all labels at the *first* position in the sequence, and `psis` (batch-size x (seqlen-1) x num-labels x num-labels), the scores for all possible pairs of labels at the remaining positions in the sequence.\n",
        "\n",
        "## Viterbi\n",
        "We are now in a position to implement the Viterbi algorithm, which consumes these local scores and gives us the highest scoring overall sequence and its corresponding score. Below, we have written a `viterbi` function that consumes these `psi0` and `psis` local scores, and which is missing code.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnBgN7WA6ggp"
      },
      "source": [
        "### **Implementation task \\#2**\n",
        "Implement a batched version of the Viterbi algorithm to compute the **max** score among all possible label sequences, and also to return the **argmax**, by filling out the `viterbi` and `backtrace` functions below. The `backtrace` function computes the sequence of labels which lead to the maximum score, given the backpointers across the viterbi table and the highest scoring label at the last time-step.\n",
        "\n",
        "Once we have a Viterbi implementation we can use the trained HMM to make predictions on the validation set! Running the evaluation code below with your Viterbi implementation should get you an F1 score above 0.76 on the validation set. While we're here, we'll also run your `viterbi` implementation on random scores to check its correctness.\n",
        "\n",
        "**TLDR**: Complete the `viterbi` and `backtrace` functions below, and then run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BLXZsQHpxdYn"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5m/w0rlpsxd7yx_97nl1gx0dfzm0000gn/T/ipykernel_57742/2546169457.py:14: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = datasets.load_metric(\"seqeval\", trust_remote_code=True)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66969dc7243f45f78ae98f0b38529cea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/439 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision =  0.852, Recall =  0.699, F1 =  0.768\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ea3ff9a731f4f6cb09ef6ee36021b49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1060 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eecd50051b3f4675adcd456f2ce3112f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saved to viterbi_vals.npy\n"
          ]
        }
      ],
      "source": [
        "def viterbi(psi0, psis):\n",
        "    \"\"\"\n",
        "    Computes the Viterbi algorithm.\n",
        "\n",
        "    args\n",
        "      - psi0: a tensor of real scores (which can be < 0), of dimension batchsize x K\n",
        "      - psis: a tensor of real scores (which can be < 0), of dimension batchsize x M-1 x K x K\n",
        "\n",
        "    returns\n",
        "      - max_scores: a batchsize tensor of max scores for each sequence\n",
        "      - preds: a batchsize x M tensor of label indices, where each index is between 0 and K-1\n",
        "    \"\"\"\n",
        "    bsz, K = psi0.size() # batchsize, nlabels\n",
        "    M = psis.size(1) + 1 # sequence length\n",
        "\n",
        "    vtable = psis.new(bsz, M, K).zero_() \n",
        "    bps = torch.zeros(bsz, M, K, dtype=torch.long, device=vtable.device)\n",
        "\n",
        "    # base case\n",
        "    vtable[:, 0].copy_(psi0)\n",
        "\n",
        "    ### BEGIN YOUR CODE HERE!!!!\n",
        "    #Your code start here\n",
        "    for m in range(1, M):\n",
        "        psis_m = psis[:, m-1]            # bsz x K x K\n",
        "        prev_v = vtable[:, m-1].unsqueeze(2)  # bsz x K x 1\n",
        "        sum_v = prev_v + psis_m               # bsz x K x K\n",
        "        max_vals, argmax_vals = sum_v.max(dim=1)  # bsz x K\n",
        "        vtable[:, m] = max_vals\n",
        "        bps[:, m] = argmax_vals\n",
        "\n",
        "    max_scores, last_labels = vtable[:, M-1].max(dim=1)\n",
        "    #Your code end here\n",
        "    ### END YOUR CODE HERE\n",
        "\n",
        "    argmax_seqs = backtrace(bps, last_labels)\n",
        "    return max_scores, argmax_seqs\n",
        "\n",
        "def backtrace(bps, last_labels):\n",
        "    \"\"\"\n",
        "    Obtain the highest scoring label sequence by tracing backward with backpointers.\n",
        "\n",
        "    args\n",
        "      - bps: batchsize x M x K\n",
        "      - last_labels: batchsize tensor of indices of highest scoring label @ final timestep\n",
        "\n",
        "    returns\n",
        "      - preds: a batchsize x M tensor containing predicted label indices\n",
        "    \"\"\"\n",
        "    ### BEGIN YOUR CODE HERE!!!!\n",
        "    #Your code start here\n",
        "    bsz, M, K = bps.size()\n",
        "    preds = torch.zeros(bsz, M, dtype=torch.long, device=bps.device)\n",
        "    preds[:, M-1] = last_labels\n",
        "    for m in reversed(range(M-1)):\n",
        "        preds[:, m] = bps[torch.arange(bsz), m+1, preds[:, m+1]]\n",
        "    #Your code end here\n",
        "    ### END YOUR CODE HERE\n",
        "    return preds\n",
        "\n",
        "\n",
        "# implement Viterbi before running the following\n",
        "eval_predictions(val_loader, hmm, val_loader.batch_sampler.nbatches)\n",
        "\n",
        "# get predictions on the test set and save\n",
        "test_loader = torch.utils.data.DataLoader(testdata, batch_size=1,\n",
        "    batch_sampler=ByLengthSampler(testdata, 'tokens', 1, shuffle=False),\n",
        "    collate_fn=collate)\n",
        "with open(\"hmm_predictions.json\", \"w\") as f:\n",
        "    json.dump(eval_predictions(test_loader, hmm, test_loader.batch_sampler.nbatches, show_f1=False), f)\n",
        "\n",
        "# run viterbi on random scores\n",
        "save_alg_outputs(alg=\"viterbi\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LbaEhgsL_ii"
      },
      "source": [
        "<!-- Do not remove this comment, it is used by the autograder: RqYJKsoTS6 -->\n",
        "\n",
        "Validation precision: ***fill in here***\n",
        "\n",
        "Validation recall: ***fill in here***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL65ZNLbNlCp"
      },
      "source": [
        "Before proceeding please download `hmm_predictions.json` and `viterbi_vals.npy` for submission to GradeScope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Upe8KFIWHCoy"
      },
      "source": [
        "# Linear-chain CRFs\n",
        "\n",
        "Now let's use linear-chain CRFs to make some predictions. Recall that feature-based linear-chain CRFs define scores at each position for every possible pair of labels given by,\n",
        "\n",
        "$$\\psi(w_{1:M}, y_m, y_{m-1}, m) = \\boldsymbol{\\theta} \\cdot \\mathbf{f}(w_{1:M}, y_m, y_{m-1}, m),$$\n",
        "\n",
        "where $\\boldsymbol{\\theta}$ is now a vector of free parameters, and the features $\\mathbf{f}$ (also a vector) can be arbitrary features extracted for the position $m$. These features are allowed to depend on the whole word sequence $w_{1:M}$, the label at position $m$, and the previous label (at position $m-1$) but nothing else.\n",
        "\n",
        "## Our particular features\n",
        "We have implemented a class for extracting features from word sequences. To reduce the number of parameters, we split the features into two parts:\n",
        "\n",
        "$$\\psi(w_{1:M}, y_m, y_{m-1}, m) = \\boldsymbol{\\theta}_{label} \\cdot \\mathbf{f}_{label}(w_{1:M}, y_m, m) + \\boldsymbol{\\theta}_{trans} \\cdot \\mathbf{f}_{trans}(w_{1:M}, y_m, y_{m-1}, m).$$\n",
        "\n",
        "The idea here is that the first term in our score will look only at the current label $y_m$, and will make use of many \"base\" features in scoring the compatibility between $w_m$ and $y_m$ (given $w_{1:M}$). In particular, we will think of $f_{label}$ as consisting of $F_{label}$ base binary features that depend on $w_m$ and $w_{1:M}$.\n",
        "\n",
        "Since we want a different local score for each pairing of these base features with each possible label for $y_m$ (of which there are $K$), we will in fact need both $\\boldsymbol{\\theta}_{label}$ and $\\mathbf{f}_{label}$ to be $KF_{label}$ dimensional, as described in the textbook. Equivalently, we can view $\\mathbf{f}_{label}$ as just being $\\mathbf{F}_{label}$ dimensional, and $\\boldsymbol{\\theta}_{label}$ as being a $K \\times F_{label}$ matrix. Then $\\boldsymbol{\\theta}_{label} \\, \\mathbf{f}_{label}$ is a matrix-vector product, which gives us a vector of scores, one for each label. And this is in fact how we have implemented it (except in our implementation $\\boldsymbol{\\theta}_{label}$ is transposed so it has $K$ columns instead of rows, since our implementation uses an `nn.Embedding`).\n",
        "\n",
        "For the transition scores, $\\boldsymbol{\\theta}_{trans} \\cdot \\mathbf{f}_{trans}(w_{1:M}, y_m, y_{m-1}, m)$, we will need a different score now for every *pair* of labels. Thus, interpreted as a matrix, $\\boldsymbol{\\theta}_{trans}$ will have $K^2$ rows, and $F_{trans}$ columns. To keep this matrix small, we use a small number of transition features. In particular, we will use only a subset of those used in $\\mathbf{f}_{label}$. This is implemented in the  `Featurizer` code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XiNjnSv0HR29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating possible features...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99143d2832204e96a9774027ef548aef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/14041 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num base features: 7141\n",
            "num transition base features 19\n",
            "featurizing dataset...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d591d152d834dd4a247f59f907588e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/14041 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "featurizing dataset...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b2c138159f74f9a9c94de07d2272d83",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "featurizing dataset...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e8749548203485498dd1b4064e6f589",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "class Featurizer:\n",
        "    def __init__(self, label_types):\n",
        "        self.label_types = label_types\n",
        "\n",
        "    def featurize_sequence_pair(self, tokens, ner_tags, map_to_indices=True):\n",
        "        \"\"\"\n",
        "        returns an M-length list of feature or feature index lists\n",
        "        \"\"\"\n",
        "        label_types = self.label_types\n",
        "        features = []\n",
        "        # we'll make base features here, which are later expanded for each label or label-bigram\n",
        "        for m, token in enumerate(tokens):\n",
        "            prev, nexxt = \"<s>\", \"</s>\" # previous and next word type\n",
        "            if m > 0:\n",
        "                prev = tokens[m-1]\n",
        "            if m < len(tokens) - 1:\n",
        "                nexxt = tokens[m+1]\n",
        "            # make simple binary/indicator base features\n",
        "            features.append([\"curr_word=%s\" % token,\n",
        "                             \"prev_word=%s\" % prev,\n",
        "                             \"next_word=%s\" % nexxt,\n",
        "                             \"isupper=%s\" % str(token[0].isupper()),\n",
        "                             \"islower=%s\" % str(token[0].islower()),\n",
        "                             \"isdigit=%s\" % str(token[0].isdigit()),\n",
        "                             \"isprevupper=%s\" % str(prev[0].isupper()),\n",
        "                             \"isprevlower=%s\" % str(prev[0].islower()),\n",
        "                             \"isprevdigit=%s\" % str(prev[0].isdigit()),\n",
        "                             \"isnextupper=%s\" % str(nexxt[0].isupper()),\n",
        "                             \"isnextlower=%s\" % str(nexxt[0].islower()),\n",
        "                             \"isnextdigit=%s\" % str(nexxt[0].isdigit()),\n",
        "                             \"always_on\"])\n",
        "        if map_to_indices:\n",
        "            return [[self.feature_type2idx[feat] for feat in feats_m\n",
        "                     if feat in self.feature_type2idx]\n",
        "                    for feats_m in features]\n",
        "        return features\n",
        "\n",
        "    def is_transition_feature(self, featname):\n",
        "        \"\"\"\n",
        "        This function identifies a subset of the features calculated in featurize_sequence_pair()\n",
        "        to use as transition features, BASED ON THEIR NAMES.\n",
        "        If you implement new features above, make sure your feature names are such\n",
        "        that they don't get repeated for each label pair, unless you want them to.\n",
        "        \"\"\"\n",
        "        return featname.startswith('al') or featname.startswith('is')\n",
        "\n",
        "    def create_all_feature_types(self, dataset, min_feat_freq=10):\n",
        "        feat_counter = Counter()\n",
        "        print(\"calculating possible features...\")\n",
        "        for example in tqdm.notebook.tqdm(dataset):\n",
        "            tokens, ner_tags = example[\"tokens\"], example[\"ner_tags\"] # tags are already indices\n",
        "            # calculate possible features per timestep\n",
        "            features = self.featurize_sequence_pair(tokens, ner_tags, map_to_indices=False)\n",
        "            for feats_m in features:\n",
        "                feat_counter.update(feats_m)\n",
        "\n",
        "        # prune features that don't occur at least min_feat_freq times\n",
        "        self.feature_types = [feat for (feat, fcount) in feat_counter.items()\n",
        "                              if fcount >= min_feat_freq]\n",
        "        # we're going to pick only a subset of base features to repeat for each transition.\n",
        "        self.ntransition_feats = sum(1 for featname in self.feature_types\n",
        "                                     if self.is_transition_feature(featname))\n",
        "        # sort the feature types so these transition features have lower indices;\n",
        "        # this way when computing transition scores we can just ignore features with\n",
        "        # indices that are too high.\n",
        "        self.feature_types.sort(\n",
        "            key=lambda featname: -int(self.is_transition_feature(featname)))\n",
        "\n",
        "        self.feature_type2idx = {feat: i for i, feat in enumerate(self.feature_types)}\n",
        "        print(\"num base features:\", len(self.feature_type2idx))\n",
        "        print(\"num transition base features\", self.ntransition_feats)\n",
        "\n",
        "    def featurize_dataset(self, dataset):\n",
        "        print(\"featurizing dataset...\")\n",
        "        featurized_dataset = []\n",
        "        for example in tqdm.notebook.tqdm(dataset):\n",
        "            tokens, ner_tags = example[\"tokens\"], example[\"ner_tags\"] # tags are already indices\n",
        "            # calculate possible features per timestep\n",
        "            features = self.featurize_sequence_pair(tokens, ner_tags, map_to_indices=True)\n",
        "            featurized_dataset.append({'featurized_sequence': features, 'ner_tags': ner_tags})\n",
        "        return FeaturizedDataset(featurized_dataset)\n",
        "\n",
        "featurizer = Featurizer(label_types)\n",
        "featurizer.create_all_feature_types(trdata)\n",
        "featurized_trdata = featurizer.featurize_dataset(trdata) # a list of dicts\n",
        "featurized_valdata = featurizer.featurize_dataset(valdata)\n",
        "featurized_testdata = featurizer.featurize_dataset(testdata)\n",
        "\n",
        "def featurized_collate(batchdictseq):\n",
        "    batchdict = batchdictseq[0]\n",
        "    # pad so all timesteps of all examples in the minibatch have the same number\n",
        "    # of features\n",
        "    max_nfeats = max(len(feats_m) for feats in batchdict['featurized_sequence']\n",
        "                     for feats_m in feats)\n",
        "    pad_idx = len(featurizer.feature_types)\n",
        "    # make batchsize x M x max_nfeats feature tensors\n",
        "    featureseqs = torch.LongTensor([[feats_m + [pad_idx] * (max_nfeats - len(feats_m))\n",
        "                                     for feats_m in feats]\n",
        "                                    for feats in batchdict['featurized_sequence']])\n",
        "    tgtseqs = torch.LongTensor(batchdict[\"ner_tags\"]) # these are already indices\n",
        "    return featureseqs, tgtseqs\n",
        "\n",
        "crf_batchsize = 64 # feel free to change this\n",
        "\n",
        "# The following DataLoaders allow for iterating over the featurized_trdata or featurized_valdata\n",
        "# defined above. These iterators will return two elements, the first of which is a sequence of\n",
        "# feature vectors for each position in the sentence, and the second of which is a sequence of labels.\n",
        "# Each feature vector will be a list of indices into all possible features in the dataset.\n",
        "# Among these indices, the first featurizer.ntransition_feats of them will correspond to\n",
        "# F_{trans}. You do not need to change anything in the code below or above if you don't want to.\n",
        "\n",
        "train_feat_loader = torch.utils.data.DataLoader(featurized_trdata, batch_size=1, # hack\n",
        "    sampler=ByLengthSampler(featurized_trdata, 'featurized_sequence', crf_batchsize, shuffle=True),\n",
        "    collate_fn=featurized_collate)\n",
        "\n",
        "val_feat_loader = torch.utils.data.DataLoader(featurized_valdata, batch_size=1,\n",
        "    sampler=ByLengthSampler(featurized_valdata, 'featurized_sequence', crf_batchsize, shuffle=False),\n",
        "    collate_fn=featurized_collate)\n",
        "\n",
        "test_feat_loader = torch.utils.data.DataLoader(featurized_testdata, batch_size=1,\n",
        "    sampler=ByLengthSampler(featurized_testdata, 'featurized_sequence', 1, shuffle=False),\n",
        "    collate_fn=featurized_collate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuwoLuMfP1VB"
      },
      "source": [
        "### The CRF module\n",
        "\n",
        "To train the CRF using gradient descent we will implement it as a PyTorch computation graph (i.e., as a subclass of `nn.Module`). The computation graph will compute the initial scores `psi0` (batch-size x num-labels) and `psis` (batch-size x (seq-len-1) x num-labels x num-labels).\n",
        "\n",
        "In the code below we have initialized two weight matrices `self.theta_label` and `self.theta_trans` using [`nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html) of size `nbase_feats x K` and `ntransition_feats x K^2`, respectively. Looking up a feature index in either of these matrices will return a vector of size `K` (or `K^2`) which is the contribution of that feature to the score $\\psi$ for each label (or pair of labels). These are used to return the initial scores `psi0` and the sequence of scores `psis`.\n",
        "\n",
        "For now you do not need to change anything in the code below, but you may want to adapt it when you implement an extension to it in the last problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UEYIKZ6xHD1s"
      },
      "outputs": [],
      "source": [
        "class CRF(nn.Module):\n",
        "    def __init__(self, K, nbase_feats, ntransition_feats):\n",
        "        super().__init__()\n",
        "        self.K = K # number of labels\n",
        "        self.nbase_feats = nbase_feats\n",
        "        self.ntransition_feats = ntransition_feats\n",
        "        # We have K weight columns for every feature, which is equivalent to duplicating features\n",
        "        # for every label, as we discussed in class.\n",
        "        self.theta_label = nn.Embedding( # reserve last feature for padding which is always zero\n",
        "            nbase_feats+1, K, padding_idx=nbase_feats)\n",
        "        self.theta_trans = nn.Embedding( # similarly have a column for each label-bigram\n",
        "            ntransition_feats+1, K**2, padding_idx=ntransition_feats)\n",
        "        # initialize with all zeros\n",
        "        self.theta_label.weight.data.zero_()\n",
        "        self.theta_trans.weight.data.zero_()\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        args\n",
        "          - X: batchsize x M x F matrix of feature indices, padded\n",
        "\n",
        "        returns\n",
        "          - psi0: a tensor of real scores (which can be < 0), of dimension batchsize x K\n",
        "          - psis: a tensor of real scores (which can be < 0), of dimension batchsize x M-1 x K x K\n",
        "        \"\"\"\n",
        "        bsz, M, _ = X.size()\n",
        "        K = self.K\n",
        "        emission_scores = self.theta_label(X).sum(2) # batchsize x M x K emission scores\n",
        "        # for transition features we only keep the lowest ntransition_feats features, as discussed\n",
        "        # in Featurizer and in the text above.\n",
        "        Xred = X.masked_fill(X > self.ntransition_feats, self.ntransition_feats)\n",
        "        transition_scores = self.theta_trans( # batchsize x M-1 x K^2 trans scores\n",
        "            Xred[:, 1:]).sum(2)\n",
        "\n",
        "        psi0 = emission_scores[:, 0]\n",
        "        psis = (emission_scores[:, 1:].unsqueeze(2)\n",
        "                + transition_scores.view(bsz, M-1, self.K, self.K))\n",
        "        return psi0, psis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGP93vkRBs4N"
      },
      "source": [
        "### **Implementation task \\# 3**\n",
        "\n",
        "We have provided a class below for training the CRF. In each training iteration, the `crf_nll` function first computes `psi0` and `psis` using the computation graph above. Then it extracts the score of gold label sequence (Y) as well as the sum over all label sequences (using the `forward_alg`) and computes the negative log-likelihood loss using them.\n",
        "\n",
        "First finish the `crf_nll` function below. Then, implement the `mle_train` function below which will train the CRF for the given number of epochs. This code should be very similar to what you implemented for the Neural Ngram and GRU models in Assignment 1, except you will use `crf_nll` to obtain the loss for each sequence in the batch. Use the `Adagrad` optimizer that we have initialized.\n",
        "\n",
        "Note that this code will not run correctly until you also implement the `forward_alg` function below. You can track the validation set performance by calling `eval_predictions` and passing `self` as the second argument. Make sure you implement **early stopping**.\n",
        "\n",
        "**TLDR:** Fill in the `crf_nll` and `mle_train` functions below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_ddOLP0ggFMZ"
      },
      "outputs": [],
      "source": [
        "class CRFModel(SequenceModel):\n",
        "    def __init__(self, K, nbase_feats, ntransition_feats):\n",
        "        self.K = K\n",
        "        self.crf = CRF(K, nbase_feats, ntransition_feats)\n",
        "\n",
        "    def gold_sequence_scores(self, Y, psi0, psis):\n",
        "        \"\"\"\n",
        "        Calculate total scores of a batch of sequences:\n",
        "            total_score(x, y) = sum_{m=1}^M psi(x, y_{m}, y_{m-1}, m)\n",
        "        args\n",
        "          - Y: batchsize x M matrix of label type indices\n",
        "          - psi0: a tensor of real scores (which can be < 0), of dimension batchsize x K\n",
        "          - psis: a tensor of real scores (which can be < 0), of dimension batchsize x M-1 x K x K\n",
        "        \"\"\"\n",
        "        bsz, M = Y.size()\n",
        "        all_example_idxs = torch.arange(bsz).to(Y.device)\n",
        "        scores = psi0[all_example_idxs, Y[:, 0]]\n",
        "        for m in range(1, M):\n",
        "            psis_m = psis[:, m-1] # bsz x K x K\n",
        "            transitions_m = Y[:, m-1:m+1] # bsz x 2\n",
        "            scores = scores + psis_m[all_example_idxs,\n",
        "                                     transitions_m[:, 0],\n",
        "                                     transitions_m[:, 1]]\n",
        "        return scores\n",
        "\n",
        "    def get_sequence_psis(self, X):\n",
        "        return self.crf(X)\n",
        "\n",
        "    def crf_nll(self, X, Y):\n",
        "        \"\"\"\n",
        "        Calculate CRF negative log likelihood.\n",
        "\n",
        "        args\n",
        "          - X: batchsize x M x F matrix of feature indices, padded\n",
        "          - Y: batchsize x M matrix of label type indices\n",
        "        returns\n",
        "         - nlls - a batchsize length tensor of negative log likelihoods\n",
        "        \"\"\"\n",
        "        psi0, psis = self.get_sequence_psis(X)\n",
        "        gold_scores = self.gold_sequence_scores(Y, psi0, psis)\n",
        "        log_Zs = forward_alg(psi0, psis)\n",
        "\n",
        "        ### Your CODE HERE!!!\n",
        "        #Your code start here\n",
        "        nlls = log_Zs - gold_scores\n",
        "        #Your code end here\n",
        "        ### END YOUR CODE HERE\n",
        "        return nlls\n",
        "    \n",
        "    def mle_train(self, trloader, valloader, epochs=10):\n",
        "        lr = 2e-1\n",
        "        weight_decay = 1e-6\n",
        "        optim = torch.optim.Adagrad(self.crf.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "        ### YOUR CODE HERE!!!\n",
        "        #Your code start here\n",
        "        import copy\n",
        "        def get_f1(dataloader, model):\n",
        "            metric = datasets.load_metric(\"seqeval\", trust_remote_code=True)\n",
        "            with torch.no_grad():\n",
        "                for (Xb, Yb) in dataloader:\n",
        "                    # Do not squeeze! Keep Xb as [batch, M, F]\n",
        "                    _, preds = model.predict(Xb)\n",
        "                    preds, Yb = preds.tolist(), Yb.tolist()\n",
        "                    goldlabels = [[label_types[g] for g in seq] for seq in Yb]\n",
        "                    predlabels = [[label_types[p] for p in seq] for seq in preds]\n",
        "                    metric.add_batch(predictions=predlabels, references=goldlabels)\n",
        "            results = metric.compute()\n",
        "            return results[\"overall_f1\"]\n",
        "\n",
        "        best_val_f1 = 0.0\n",
        "        best_state = None\n",
        "        patience = 0\n",
        "        for epoch in range(epochs):\n",
        "            self.crf.train()\n",
        "            for (X, Y) in tqdm.notebook.tqdm(trloader, total=trloader.sampler.nbatches):\n",
        "                # Do not squeeze; X is expected to be 3-D.\n",
        "                optim.zero_grad()\n",
        "                loss = self.crf_nll(X, Y).mean()\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "\n",
        "            print(f\"Epoch {epoch} complete. Checking validation set:\")\n",
        "            self.crf.eval()\n",
        "            eval_predictions(valloader, self)\n",
        "\n",
        "            val_f1 = get_f1(valloader, self)\n",
        "            print(f\"Validation F1 = {val_f1:.3f}\")\n",
        "\n",
        "            if val_f1 > best_val_f1:\n",
        "                best_val_f1 = val_f1\n",
        "                best_state = copy.deepcopy(self.crf.state_dict())\n",
        "                patience = 0\n",
        "            else:\n",
        "                patience += 1\n",
        "                if patience > 2:\n",
        "                    print(\"Early stopping!\")\n",
        "                    break\n",
        "\n",
        "        if best_state is not None:\n",
        "            self.crf.load_state_dict(best_state)\n",
        "        #Your code end here\n",
        "        ### END YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS9VG35wFITN"
      },
      "source": [
        "## The forward algorithm\n",
        "Before your `crf_nll` function will run, you will need to implement the forward algorithm, which will calculate the log of the sum of all the exponentiated sequence scores. We provide the function `forward_alg`, which is missing code, below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDr5aM2iDiAo"
      },
      "source": [
        "### **Implementation Task \\#4**\n",
        " The `forward_alg` function below accepts two arguments: the scores for all labels at the first position in the sequence `psi0` (batch-size x num-labels) and the scores for all possible pairs of labels at each position in the sequence `psis` (batch-size x (seqlen-1) x num-labels x num-labels).\n",
        "\n",
        "Make sure you only use **PyTorch operations** since we will be backpropagating through the forward algorithm.\n",
        "\n",
        "Once you have implemented the forward algorithm you can train your model, by running the code below. Your implementation should get an F1 score close to 0.80 on the validation set.\n",
        "\n",
        "**TLDR:** Complete the `forward_algorithm` function above, and run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HZ9k5zu2JJyV"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c756af1d180b4c098ee9729bf1ee748c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/260 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 complete. Checking validation set:\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff5c06681d274a38bf85389495764320",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision =  0.790, Recall =  0.746, F1 =  0.768\n",
            "Validation F1 = 0.768\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfef9aae579e46739b519d532f806f7c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/260 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 complete. Checking validation set:\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc79c3e4432940cfaf7fae7363d7e3bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision =  0.731, Recall =  0.715, F1 =  0.723\n",
            "Validation F1 = 0.723\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ada9a9a0c22a4f55a180fa8990493d02",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/260 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 complete. Checking validation set:\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bee4aa709101453e86fe25bcd96c59f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision =  0.807, Recall =  0.777, F1 =  0.792\n",
            "Validation F1 = 0.792\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b09361363f9940e0a245e5d1bbc6a5e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/260 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 complete. Checking validation set:\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3f70afbad08489587598e403ceb6e1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision =  0.809, Recall =  0.772, F1 =  0.790\n",
            "Validation F1 = 0.790\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84ee793c0f7f455996226d2f9f2f6dfb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/260 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 complete. Checking validation set:\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6287b4851ab48c9a5de8e43ceefa1f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision =  0.799, Recall =  0.777, F1 =  0.788\n",
            "Validation F1 = 0.788\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96b94996becd489ab785818f981c3986",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/260 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 complete. Checking validation set:\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24c4e0ea8569478c93d4feb21636fd12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision =  0.803, Recall =  0.781, F1 =  0.792\n",
            "Validation F1 = 0.792\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7e0b3ba05fa444ca593aeea60ec9595",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/260 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 complete. Checking validation set:\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "daff9fab5ef0446bb730492c2807e544",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision =  0.811, Recall =  0.790, F1 =  0.800\n",
            "Validation F1 = 0.800\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2dafcb6770740899101cdaf7920f590",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/260 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 complete. Checking validation set:\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44571d32daa74a57a17b693191452798",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision =  0.824, Recall =  0.784, F1 =  0.804\n",
            "Validation F1 = 0.804\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db2ffe5b462e404ea8f20874a61e90ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/260 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 complete. Checking validation set:\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fcae339dd44480c8dc631e52d621828",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision =  0.806, Recall =  0.792, F1 =  0.799\n",
            "Validation F1 = 0.799\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86143483527e4e9b9d07cfffbeab4cbf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/260 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 complete. Checking validation set:\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0279e0d8999c4f30a9b4c4507adfc81f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/90 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision =  0.807, Recall =  0.790, F1 =  0.799\n",
            "Validation F1 = 0.799\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7ac0d3ac9e0484699bf21697561afae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1060 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/opt/anaconda3/envs/deeplearning/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57435a5a995148b8b285c7f30280f7fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saved to forward_vals.npy\n"
          ]
        }
      ],
      "source": [
        "def forward_alg(psi0, psis):\n",
        "    \"\"\"\n",
        "    Computes the forward algorithm.\n",
        "\n",
        "    args\n",
        "      - psi0: a tensor of real scores (which can be < 0), of dimension batchsize x K\n",
        "      - psis: a tensor of real scores (which can be < 0), of dimension batchsize x M-1 x K x K\n",
        "\n",
        "    returns\n",
        "      - log_Zs: a batchsize tensor of the log of the sum of the possible scores for each x sequence\n",
        "    \"\"\"\n",
        "    bsz, K = psi0.size() # batchsize, nlabels\n",
        "    M = psis.size(1) + 1 # sequence length\n",
        "\n",
        "    # make our forward table data structure. it will have entries for only the CURRENT step,\n",
        "    # since we never need to trace backward; we just want the log of the sum of all the exponentiated scores.\n",
        "    # moreover, since the base case is the sum of scores of any sequence of length 1\n",
        "    # ending in label k, and that is just the score of the first position having label k,\n",
        "    # we will simply set alpha to psi0\n",
        "    alpha = psi0 # bsz x K stores sum of all possible scores at CURRENT time step\n",
        "\n",
        "    # update alpha for each remaining time step\n",
        "\n",
        "    # Note that we want the log of the sum of exponentiated scores.\n",
        "    # So when adding scores for different labels, intuitively you want to first take an exp,\n",
        "    # then sum, and then take a log again.\n",
        "    # You should use torch.logsumexp for this, which is much more stable:\n",
        "    # https://pytorch.org/docs/stable/generated/torch.logsumexp.html\n",
        "\n",
        "    ### BEGIN YOUR CODE HERE!!!\n",
        "    for m in range(1, M):\n",
        "        psis_m = psis[:, m-1]               # bsz x K x K\n",
        "        alpha_expanded = alpha.unsqueeze(2) # bsz x K x 1\n",
        "        sum_ = alpha_expanded + psis_m      # bsz x K x K\n",
        "        alpha = torch.logsumexp(sum_, dim=1) # bsz x K\n",
        "\n",
        "    log_Zs = torch.logsumexp(alpha, dim=1)  # bsz\n",
        "    ### END YOUR CODE HERE\n",
        "\n",
        "    ### END YOUR CODE HERE\n",
        "\n",
        "    # at this point your alpha should be bsz x K, representing the log of the sum of\n",
        "    # exponentiated scores for each sequence ending at each possible label.\n",
        "    # we now obtain total score overall by log-sum-exping over all the possible end labels.\n",
        "    log_Zs = torch.logsumexp(alpha, dim=1) # bsz\n",
        "    return log_Zs\n",
        "\n",
        "\n",
        "device = torch.device('cpu')\n",
        "crf = CRFModel(len(label_types), len(featurizer.feature_types), featurizer.ntransition_feats)\n",
        "crf.mle_train(train_feat_loader, val_feat_loader, epochs=10)\n",
        "\n",
        "# get predictions on the test set and save\n",
        "with open(\"crf_predictions.json\", \"w\") as f:\n",
        "    json.dump(eval_predictions(test_feat_loader, crf, show_f1=False), f)\n",
        "\n",
        "# run the forward algorithm on random scores\n",
        "save_alg_outputs(alg=\"forward\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgPoMzanOskN"
      },
      "source": [
        "<!-- Do not remove this comment, it is used by the autograder: RqYJKsoTS6 -->\n",
        "\n",
        "CRF validation precision: ***fill in here***\n",
        "\n",
        "CRF validation recall: ***fill in here***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLuqhcEH0zRa"
      },
      "source": [
        "Before moving on, please download `crf_predictions.json` and `forward_vals.npy`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLoiXBWMaSPc"
      },
      "source": [
        "# Experimentation: 1-Page Report\n",
        "\n",
        "Now it's time for you to experiment.  Try to improve the CRF validation score further. You may either modify the CRF classes above, or copy them in new code cells below and modify them there.\n",
        "\n",
        "**NOTE:** We will award at least 7 of the 10 points if your improved model reaches a F1 score of at least 0.73 on the hidden test cases on Gradescope.\n",
        "\n",
        "Here are some ideas to try out:\n",
        "* More or different features. You can modify the code in `Featurizer` to accomplish this.\n",
        "* Neural CRFs: instead of using linear functions of features to compute your psi local scores, create a new `NeuralCRF` module (which inherits from `nn.Module`) and which computes scores using a neural network of some kind.\n",
        "  * If you do this, you will likely want to use a different DataLoader from the one used with the feature-based CRF. The following code will create a DataLoader which, when iterated over, returns a `(batchsize x M word indices, batchsize x M label indices)` tuple instead of a `(batchsize x M x F feature indices, batchsize x M label indices)` tuple:\n",
        "\n",
        "  ```\n",
        "  train_loader = torch.utils.data.DataLoader(trdata, batch_size=1,\n",
        "       batch_sampler=ByLengthSampler(trdata, 'tokens', batchsize, shuffle=True),\n",
        "       collate_fn=collate)\n",
        "     ```\n",
        "\n",
        "Note that a significant part of the the test set consists of examples from a different domain. So try to think of features / improvements which would transfer to other domains (such as encyclopedic text).\n",
        "\n",
        "For this section, you will submit a write-up describing the extensions and/or modifications that you tried.  Your write-up should be **1-page maximum** in length and should be submitted in PDF format.  You may use any editor you like, but we recommend using LaTeX and working in an environment like Overleaf.\n",
        "For full credit, your write-up should include:\n",
        "1.   A concise and precise description of the extension that you tried.\n",
        "2.   A motivation for why you believed this approach might improve your model.\n",
        "3.   A discussion of whether the extension was effective and/or an analysis of the results.  This will generally involve some combination of tables, learning curves, etc.\n",
        "4.   A bottom-line summary of your results comparing F1 score of your improvement to the original CRF.\n",
        "The purpose of this exercise is to experiment, so feel free to try/ablate multiple of the suggestions above as well as any others you come up with!\n",
        "When you submit the file, please name it `report.pdf`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHTOfrCG8CRF"
      },
      "source": [
        "### Submission\n",
        "\n",
        "Upload a submission with the following files to Gradescope:\n",
        "* proj_2.ipynb (rename to match this exactly)\n",
        "* hmm_predictions.json\n",
        "* crf_predictions.json (this should also include all improvements from your exploration)\n",
        "* viterbi_vals.npy\n",
        "* forward_vals.npy\n",
        "* report.pdf\n",
        "\n",
        "You can upload files individually or as part of a zip file, but if using a zip file be sure you are zipping the files directly and not a folder that contains them.\n",
        "\n",
        "Be sure to check the output of the autograder after it runs.  It should confirm that no files are missing and that the output files have the correct format.  Note that the test set F1 scores shown by the autograder are on different data from your validation set.  Don't worry if the values seem worse. We will compare your score on the test set to our model's score and assign points based on that."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0075c205c0434cd3b5799924bc82f493": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06e8d9144da14c8da7489a2556e5457c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b9ce3e63edf4b07b92c62d351502bf0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d668b611b7f416a95b3299856ba3e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7575e83a7254f17a644d41a42d9449f",
            "max": 311883,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_951581a5c0e04bc88b77c5c4938c3800",
            "value": 311883
          }
        },
        "0df2d42685fc423a984985f71733e4c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce8941fd049b4f26ad118d952fab0273",
              "IPY_MODEL_2a96e5b30c5045ef8695bcfc4bafe00b",
              "IPY_MODEL_b8a8449c5cd84e1295f3c3dd7b3dc1f3"
            ],
            "layout": "IPY_MODEL_c7eed34ed19d4c978e1ca01b48f22aa9"
          }
        },
        "0e3a6101cd064827bf5ddba9e8c6b7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b6a2ac6983745a48a269bf4d6a7dc77",
            "placeholder": "​",
            "style": "IPY_MODEL_ed4deccbde194ff0b69c4d15ece2e6e3",
            "value": " 1.23M/1.23M [00:00&lt;00:00, 2.79MB/s]"
          }
        },
        "14becfbe34674619a8f0cc8974a929f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17a07ecc939a4607a85a5b34550847ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b6a2ac6983745a48a269bf4d6a7dc77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bde6f946d474cdb9a70d02417b6e8d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a96e5b30c5045ef8695bcfc4bafe00b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b9ce3e63edf4b07b92c62d351502bf0",
            "max": 3453,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8137f6ce5fe9446d919239bfafb666bc",
            "value": 3453
          }
        },
        "31a59ec567194230adf4e7d22b4e86d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "361459d739954d48b348b054a7a3136e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36536a1aa8644836837ca6b8601b39e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b061c108ab249f3826419ea224fd054": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b3eb0307f1242c18f51cded81b3ff9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7a0c13ef3dd4966895d437df1cd15a2",
            "placeholder": "​",
            "style": "IPY_MODEL_7cb7c5b17e1f4c85a89998c33b5f6b30",
            "value": "Downloading data: 100%"
          }
        },
        "3dc4decface443b4b83da1830217f256": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f17611c5c1894a158c1810a071c7ed26",
              "IPY_MODEL_8fd0e19e6ce74aacb5f8f9b17c5a906b",
              "IPY_MODEL_4c914b6f5dfd4962a1438f736db1004a"
            ],
            "layout": "IPY_MODEL_3b061c108ab249f3826419ea224fd054"
          }
        },
        "4c914b6f5dfd4962a1438f736db1004a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75b55292650242c4a982e22b99f7b75d",
            "placeholder": "​",
            "style": "IPY_MODEL_14becfbe34674619a8f0cc8974a929f5",
            "value": " 14041/14041 [00:00&lt;00:00, 60824.74 examples/s]"
          }
        },
        "4dfc08556897472bbc2cdda58aef5b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5202ccc43ad54e3e9bcbf104e845d85a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "525e104d92e9455eac4e5fc46198bdcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0075c205c0434cd3b5799924bc82f493",
            "placeholder": "​",
            "style": "IPY_MODEL_db071929ecc34879a4f58cbb151335d0",
            "value": "Generating validation split: 100%"
          }
        },
        "57bd92df3e794fefbd5ee6024b7f75a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd040b81e72e4078b6a4c39a36b55cf7",
            "max": 283307,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36536a1aa8644836837ca6b8601b39e3",
            "value": 283307
          }
        },
        "61869919871e417f9aef1c48cb85967b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b3eb0307f1242c18f51cded81b3ff9f",
              "IPY_MODEL_0d668b611b7f416a95b3299856ba3e4b",
              "IPY_MODEL_649ed9285d3845b0a1cb537eb185039d"
            ],
            "layout": "IPY_MODEL_ec7646544c644a6c89d501f35ac3d877"
          }
        },
        "61941d4e7273429dbde90078d39cc7b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6242e1267f5c40909826cbf7bf02e723": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64611014d6c24b1f952af475573ce7ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e973317461e459396fc302090f4323d",
            "max": 3250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a01d0993265248569e958aa0eb58a8cf",
            "value": 3250
          }
        },
        "649ed9285d3845b0a1cb537eb185039d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6242e1267f5c40909826cbf7bf02e723",
            "placeholder": "​",
            "style": "IPY_MODEL_ea9b2c94235f454d9bcdaf4cdca0028d",
            "value": " 312k/312k [00:00&lt;00:00, 1.70MB/s]"
          }
        },
        "65e6df0e0b604a99a23294901acd9e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68cda39013b54ab8a518dc947734c91b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7312b7cfca104be7bd309c03c3a48e4c",
              "IPY_MODEL_57bd92df3e794fefbd5ee6024b7f75a4",
              "IPY_MODEL_fc5e733df89d4df6aa7d003ce3fdae5f"
            ],
            "layout": "IPY_MODEL_a76bb0bbb47946aa9d28220ae3f701e4"
          }
        },
        "6a86b21eba374c0fae5d64a0e2ae01f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b93152dee384f2091b0c3bb8137bfaf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f57783a3fd84d6d81cea97b459cfe73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3db8635d83c4c4989cfbde399e36299",
            "placeholder": "​",
            "style": "IPY_MODEL_5202ccc43ad54e3e9bcbf104e845d85a",
            "value": "Downloading data: 100%"
          }
        },
        "72feee3b2b6c40c2a25d3519e828b39a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7312b7cfca104be7bd309c03c3a48e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06e8d9144da14c8da7489a2556e5457c",
            "placeholder": "​",
            "style": "IPY_MODEL_72feee3b2b6c40c2a25d3519e828b39a",
            "value": "Downloading data: 100%"
          }
        },
        "75b55292650242c4a982e22b99f7b75d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cb7c5b17e1f4c85a89998c33b5f6b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8137f6ce5fe9446d919239bfafb666bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8581f9998bf1468b9d2cfc480dfde65e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b1dad8582884cbda6e476b5b3d52eeb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e973317461e459396fc302090f4323d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f7c8ca70c0c4083bfe80715f444868c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_525e104d92e9455eac4e5fc46198bdcd",
              "IPY_MODEL_64611014d6c24b1f952af475573ce7ce",
              "IPY_MODEL_ee5fe82b8add4905a682270baa3e6401"
            ],
            "layout": "IPY_MODEL_e43cd6e248574d9fb1fbe08c540d80f7"
          }
        },
        "8fd0e19e6ce74aacb5f8f9b17c5a906b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e451f908a44c465a831258bff2c94673",
            "max": 14041,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0a618b3f1bd42159ea8a7b5d6c8874a",
            "value": 14041
          }
        },
        "93033a1e381b49ab9971e8bae6d3011c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "951581a5c0e04bc88b77c5c4938c3800": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a01d0993265248569e958aa0eb58a8cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a76bb0bbb47946aa9d28220ae3f701e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7575e83a7254f17a644d41a42d9449f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8a8449c5cd84e1295f3c3dd7b3dc1f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b93152dee384f2091b0c3bb8137bfaf",
            "placeholder": "​",
            "style": "IPY_MODEL_f1675ab219d348c0b4c7bf5cb97f1c26",
            "value": " 3453/3453 [00:00&lt;00:00, 43793.18 examples/s]"
          }
        },
        "c3db8635d83c4c4989cfbde399e36299": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4bdb4353323484585bb50b68d5764c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f57783a3fd84d6d81cea97b459cfe73",
              "IPY_MODEL_d8c42315171d4e5daddea712222661a1",
              "IPY_MODEL_0e3a6101cd064827bf5ddba9e8c6b7f3"
            ],
            "layout": "IPY_MODEL_361459d739954d48b348b054a7a3136e"
          }
        },
        "c7a0c13ef3dd4966895d437df1cd15a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7eed34ed19d4c978e1ca01b48f22aa9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd040b81e72e4078b6a4c39a36b55cf7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce8941fd049b4f26ad118d952fab0273": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31a59ec567194230adf4e7d22b4e86d5",
            "placeholder": "​",
            "style": "IPY_MODEL_4dfc08556897472bbc2cdda58aef5b6b",
            "value": "Generating test split: 100%"
          }
        },
        "d8c42315171d4e5daddea712222661a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61941d4e7273429dbde90078d39cc7b2",
            "max": 1227788,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65e6df0e0b604a99a23294901acd9e19",
            "value": 1227788
          }
        },
        "db071929ecc34879a4f58cbb151335d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e43cd6e248574d9fb1fbe08c540d80f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e451f908a44c465a831258bff2c94673": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea9b2c94235f454d9bcdaf4cdca0028d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec7646544c644a6c89d501f35ac3d877": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed4deccbde194ff0b69c4d15ece2e6e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee5fe82b8add4905a682270baa3e6401": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17a07ecc939a4607a85a5b34550847ba",
            "placeholder": "​",
            "style": "IPY_MODEL_6a86b21eba374c0fae5d64a0e2ae01f4",
            "value": " 3250/3250 [00:00&lt;00:00, 44046.85 examples/s]"
          }
        },
        "f0a618b3f1bd42159ea8a7b5d6c8874a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1675ab219d348c0b4c7bf5cb97f1c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f17611c5c1894a158c1810a071c7ed26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b1dad8582884cbda6e476b5b3d52eeb",
            "placeholder": "​",
            "style": "IPY_MODEL_1bde6f946d474cdb9a70d02417b6e8d9",
            "value": "Generating train split: 100%"
          }
        },
        "fc5e733df89d4df6aa7d003ce3fdae5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8581f9998bf1468b9d2cfc480dfde65e",
            "placeholder": "​",
            "style": "IPY_MODEL_93033a1e381b49ab9971e8bae6d3011c",
            "value": " 283k/283k [00:00&lt;00:00, 1.44MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
